{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from argparse import ArgumentParser\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "def load_data(input_file):\n",
    "    d = unpickle(input_file)\n",
    "    x = d['data']\n",
    "    y = d['labels']\n",
    "#     x = np.dstack((x[:, :4096], x[:, 4096:8192], x[:, 8192:]))\n",
    "#     x = x.reshape((x.shape[0], 64, 64, 3))\n",
    "    x = np.dstack((x[:, :1024], x[:, 1024:2048], x[:, 2048:]))\n",
    "    x = x.reshape((x.shape[0], 32, 32, 3))\n",
    "    return x, y\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def split_dataset(features, labels, training = 0.8, validation = 0.3):\n",
    "    rnd_indices = np.random.rand(len(labels)) < training\n",
    "    train_x = features[rnd_indices]\n",
    "    train_y = labels[rnd_indices]\n",
    "    remain_x = features[~rnd_indices]\n",
    "    remain_y = labels[~rnd_indices]\n",
    "    \n",
    "    rnd_indices2 = np.random.rand(len(remain_y)) < validation\n",
    "    val_x = remain_x[rnd_indices2]\n",
    "    val_y = remain_y[rnd_indices2]\n",
    "    test_x = remain_x[~rnd_indices2]\n",
    "    test_y = remain_y[~rnd_indices2]\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters\n",
    "\n",
    "_LR = 0.01\n",
    "_EPOCH = 60\n",
    "_BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from binary files\n",
    "\n",
    "directory = '/home/tpc2/Downloads/32*32/training_data'\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(10):\n",
    "    i = i + 1 \n",
    "    x, y = load_data(directory + '/train_data_batch_%d' % i)\n",
    "    X.extend(x)\n",
    "    Y.extend(y)\n",
    "    print('%d out of 10' % i)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = dense_to_one_hot(Y, 1000)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "train_x, train_y, val_x, val_y, test_x, test_y = split_dataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = train_datagen.flow(train_x, train_y, batch_size=_BATCH_SIZE)\n",
    "validation_generator = test_datagen.flow(val_x, val_y, batch_size=_BATCH_SIZE)\n",
    "test_generator = test_datagen.flow(test_x, test_y, batch_size=_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(32,32,3), pooling=None, classes=1000)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(lr = _LR, momentum = 0.9)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    # Reduce the learning rate if training plateaues.\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose = 1),\n",
    "   \n",
    "    # Early stopping\n",
    "    tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 1, mode = 'auto', baseline = None),\n",
    "    \n",
    "    # Tensorboard\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_grads=False, write_images=False)\n",
    "    ]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs =_EPOCH,\n",
    "        callbacks = callbacks,\n",
    "        validation_data = validation_generator)\n",
    "\n",
    "print('\\n')\n",
    "score = model.evaluate_generator(test_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
